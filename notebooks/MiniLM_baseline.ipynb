{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ir_datasets\n",
    "from datetime import datetime\n",
    "from src.dataloader import IrDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CERerankingEvaluator\n",
    "from sentence_transformers import util"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"microsoft/MiniLM-L12-H384-uncased\"\n",
    "train_batch_size = 32\n",
    "num_epochs = 1\n",
    "model_save_path = (\n",
    "    \"output/training_ms-marco_cross-encoder-\"\n",
    "    + model_name.replace(\"/\", \"-\")\n",
    "    + \"-\"\n",
    "    + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = IrDataset(ir_datasets.load(\"msmarco-passage/train/judged\"))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size)\n",
    "\n",
    "eval_dataset1 = IrDataset(ir_datasets.load(\"msmarco-passage/trec-dl-2019/judged\"))\n",
    "eval_dataset2 = IrDataset(ir_datasets.load(\"msmarco-passage/trec-dl-2020/judged\"))\n",
    "\n",
    "\n",
    "def create_samples(dataset: IrDataset):\n",
    "    queries = dataset.query_iter\n",
    "    docs = dataset.docs_iter\n",
    "    samples = {}\n",
    "    for i in range(len(dataset)):\n",
    "        samples[qid] = {\"query\": queries[qid], \"positive\": set(), \"negative\": set()}\n",
    "\n",
    "\n",
    "# Bon j'arrive pas trop, j'vais copier le code du gars\n",
    "# mais nous yet on doit le faire l'eval qui se passe pendant le train sur les deux trec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gzip\n",
    "data_folder = \"./data\"\n",
    "train_eval_filepath = os.path.join(data_folder, 'msmarco-qidpidtriples.rnd-shuf.train-eval.tsv.gz')\n",
    "if not os.path.exists(train_eval_filepath):\n",
    "    print(\"Download \"+os.path.basename(train_eval_filepath))\n",
    "    util.http_get('https://sbert.net/datasets/msmarco-qidpidtriples.rnd-shuf.train-eval.tsv.gz', train_eval_filepath)\n",
    "\n",
    "dev_samples = {}\n",
    "with gzip.open(train_eval_filepath, 'rt') as fIn:\n",
    "    for line in fIn:\n",
    "        qid, pos_id, neg_id = line.strip().split()\n",
    "\n",
    "        if qid not in dev_samples and len(dev_samples) < num_dev_queries:\n",
    "            dev_samples[qid] = {'query': queries[qid], 'positive': set(), 'negative': set()}\n",
    "\n",
    "        if qid in dev_samples:\n",
    "            dev_samples[qid]['positive'].add(corpus[pos_id])\n",
    "\n",
    "            if len(dev_samples[qid]['negative']) < num_max_dev_negatives:\n",
    "                dev_samples[qid]['negative'].add(corpus[neg_id])\n",
    "                \n",
    "=> Bon en"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CrossEncoder(model_name, num_labels=1, max_length=512)\n",
    "evaluator = CERerankingEvaluator(dev_samples, name=\"train-eval\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
