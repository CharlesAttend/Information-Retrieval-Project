{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install ir_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ir_datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [MSMARCO Passage](https://microsoft.github.io/msmarco/)\n",
    "\n",
    "*Microsoft MAchine Reading COmprehension Dataset*\n",
    "\n",
    "The MSMARCO-passage dataset contains about 8.8 million passages (average length: 73.1 words) and about 1 million natural language queries (average length: 7.5 words). Most relevance judgments are shallow (typically at most 1-2 per query), but the TREC Deep Learning track adds deep judgments. Evaluation typically conducted using MRR@10.\n",
    "\n",
    "https://ceur-ws.org/Vol-1773/CoCoNIPS_2016_paper9.pdf\n",
    "\n",
    "https://ir-datasets.com/msmarco-passage.html\n",
    "\n",
    "https://ir-datasets.com/msmarco-passage-v2.html (128 millions de passages LOL)\n",
    "\n",
    "We use the dev set (∼ 7k queries) for our empirical evaluation.  The passage corpus of MSMARCO is shared with TREC DL’19 and DL’20 collections with 43 and 54 queries respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Please confirm you agree to the MSMARCO data usage agreement found at <http://www.msmarco.org/dataset.aspx>\n",
      "[INFO] If you have a local copy of https://msmarco.blob.core.windows.net/msmarcoranking/queries.tar.gz, you can symlink it here to avoid downloading it again: /home/charles/.ir_datasets/downloads/c177b2795d5f2dcc524cf00fcd973be1\n",
      "[INFO] [starting] https://msmarco.blob.core.windows.net/msmarcoranking/queries.tar.gz\n",
      "[INFO] [finished] https://msmarco.blob.core.windows.net/msmarcoranking/queries.tar.gz: [00:11] [18.9MB] [1.58MB/s]\n",
      "                                                                                                \r"
     ]
    }
   ],
   "source": [
    "dataset = ir_datasets.load(\"msmarco-passage/dev\")\n",
    "for query in dataset.queries_iter():\n",
    "    query # namedtuple<query_id, text>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [TREC Deep Learning tracks](https://microsoft.github.io/msmarco/TREC-Deep-Learning)\n",
    "\n",
    "Utilisé dans le papier :\n",
    "- TREC DL'19 :\n",
    "    - Papier : [Overview of the TREC 2019 Deep Learning track](https://arxiv.org/abs/2003.07820)\n",
    "    - Site : https://microsoft.github.io/msmarco/TREC-Deep-Learning-2019\n",
    "- TREC DL'20 :\n",
    "    - Papier : [Overview of the TREC 2020 Deep Learning track](https://arxiv.org/abs/2102.07662)\n",
    "    - Site : https://microsoft.github.io/msmarco/TREC-Deep-Learning-2020\n",
    "\n",
    "Note : pourquoi ne pas essayer sur les données plus récentes, à savoir : 2021, 2022, 2023 ? (si relevant et qu'on a le temps)\n",
    "\n",
    "~~On trouve les jeux de données dans ir-datasets aussi, mais il y en a plusieurs, lequel ?~~\n",
    "~~Utilise ctrl + f~~\n",
    "\n",
    "Visiblement tout est dérivé de MSMARCO... (ne prendre que MSMARCO Passage ?)\n",
    "\n",
    "| TREC DL'19                                                                         | TREC DL'20                                                                         |\n",
    "|------------------------------------------------------------------------------------|------------------------------------------------------------------------------------|\n",
    "| https://ir-datasets.com/msmarco-document.html#msmarco-document/trec-dl-2019        | https://ir-datasets.com/msmarco-document.html#msmarco-document/trec-dl-2020        |\n",
    "| https://ir-datasets.com/msmarco-document-v2.html#msmarco-document-v2/trec-dl-2019  | https://ir-datasets.com/msmarco-document-v2.html#msmarco-document-v2/trec-dl-2020  |\n",
    "| https://ir-datasets.com/msmarco-passage.html#msmarco-passage/trec-dl-2019          |https://ir-datasets.com/msmarco-passage.html#msmarco-passage/trec-dl-2020           |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
