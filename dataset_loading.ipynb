{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install ir_datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [MSMARCO Passage](https://microsoft.github.io/msmarco/)\n",
    "\n",
    "*Microsoft MAchine Reading COmprehension Dataset*\n",
    "\n",
    "The MSMARCO-passage dataset contains about 8.8 million passages (average length: 73.1 words) and about 1 million natural language queries (average length: 7.5 words). Most relevance judgments are shallow (typically at most 1-2 per query), but the TREC Deep Learning track adds deep judgments. Evaluation typically conducted using MRR@10.\n",
    "\n",
    "https://ceur-ws.org/Vol-1773/CoCoNIPS_2016_paper9.pdf\n",
    "\n",
    "https://ir-datasets.com/msmarco-passage.html\n",
    "\n",
    "https://ir-datasets.com/msmarco-passage-v2.html (128 millions de passages LOL)\n",
    "\n",
    "We use the dev set (∼ 7k queries) for our empirical evaluation.  The passage corpus of MSMARCO is shared with TREC DL’19 and DL’20 collections with 43 and 54 queries respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = ir_datasets.load(\"msmarco-passage/train\")\n",
    "# for query in dataset.queries_iter():\n",
    "#     query # namedtuple<query_id, text>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [TREC Deep Learning tracks](https://microsoft.github.io/msmarco/TREC-Deep-Learning)\n",
    "\n",
    "Utilisé dans le papier :\n",
    "- TREC DL'19 :\n",
    "    - Papier : [Overview of the TREC 2019 Deep Learning track](https://arxiv.org/abs/2003.07820)\n",
    "    - Site : https://microsoft.github.io/msmarco/TREC-Deep-Learning-2019\n",
    "- TREC DL'20 :\n",
    "    - Papier : [Overview of the TREC 2020 Deep Learning track](https://arxiv.org/abs/2102.07662)\n",
    "    - Site : https://microsoft.github.io/msmarco/TREC-Deep-Learning-2020\n",
    "\n",
    "Note : pourquoi ne pas essayer sur les données plus récentes, à savoir : 2021, 2022, 2023 ? (si relevant et qu'on a le temps)\n",
    "\n",
    "~~On trouve les jeux de données dans ir-datasets aussi, mais il y en a plusieurs, lequel ?~~\n",
    "~~Utilise ctrl + f~~\n",
    "\n",
    "Visiblement tout est dérivé de MSMARCO... (ne prendre que MSMARCO Passage ?)\n",
    "\n",
    "| TREC DL'19                                                                         | TREC DL'20                                                                         |\n",
    "|------------------------------------------------------------------------------------|------------------------------------------------------------------------------------|\n",
    "| https://ir-datasets.com/msmarco-document.html#msmarco-document/trec-dl-2019        | https://ir-datasets.com/msmarco-document.html#msmarco-document/trec-dl-2020        |\n",
    "| https://ir-datasets.com/msmarco-document-v2.html#msmarco-document-v2/trec-dl-2019  | https://ir-datasets.com/msmarco-document-v2.html#msmarco-document-v2/trec-dl-2020  |\n",
    "| https://ir-datasets.com/msmarco-passage.html#msmarco-passage/trec-dl-2019          |https://ir-datasets.com/msmarco-passage.html#msmarco-passage/trec-dl-2020           |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tempory/Information-Retrieval-Project/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import ir_datasets\n",
    "from src.dataloader import IrDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ir_datasets.load(\"msmarco-passage/train/judged\")\n",
    "dataset_torch = IrDataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'Dataset' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader(dataset, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m X, y \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(X, y)\n",
      "File \u001b[0;32m/tempory/Information-Retrieval-Project/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:351\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# map-style\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[39mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 351\u001b[0m         sampler \u001b[39m=\u001b[39m RandomSampler(dataset, generator\u001b[39m=\u001b[39;49mgenerator)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    352\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    353\u001b[0m         sampler \u001b[39m=\u001b[39m SequentialSampler(dataset)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/tempory/Information-Retrieval-Project/.venv/lib/python3.9/site-packages/torch/utils/data/sampler.py:106\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacement, \u001b[39mbool\u001b[39m):\n\u001b[1;32m    103\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mreplacement should be a boolean value, but got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mreplacement=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacement))\n\u001b[0;32m--> 106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_samples, \u001b[39mint\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    107\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnum_samples should be a positive integer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mvalue, but got num_samples=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples))\n",
      "File \u001b[0;32m/tempory/Information-Retrieval-Project/.venv/lib/python3.9/site-packages/torch/utils/data/sampler.py:114\u001b[0m, in \u001b[0;36mRandomSampler.num_samples\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnum_samples\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[1;32m    112\u001b[0m     \u001b[39m# dataset size might change at runtime\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_samples \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_source)\n\u001b[1;32m    115\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_samples\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'Dataset' has no len()"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=32)\n",
    "for X, y in dataloader:\n",
    "    print(X, y)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fuck ir dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Please confirm you agree to the MSMARCO data usage agreement found at <http://www.msmarco.org/dataset.aspx>\n",
      "[INFO] If you have a local copy of https://msmarco.blob.core.windows.net/msmarcoranking/qrels.train.tsv, you can symlink it here to avoid downloading it again: /users/Etu6/21216136/.ir_datasets/downloads/733fb9fe12d93e497f7289409316eccf\n",
      "[INFO] [starting] https://msmarco.blob.core.windows.net/msmarcoranking/qrels.train.tsv\n",
      "[INFO] [finished] https://msmarco.blob.core.windows.net/msmarcoranking/qrels.train.tsv: [00:06] [10.6MB] [1.60MB/s]\n",
      "[INFO] If you have a local copy of https://msmarco.blob.core.windows.net/msmarcoranking/top1000.train.tar.gz, you can symlink it here to avoid downloading it again: /users/Etu6/21216136/.ir_datasets/downloads/d99fdbd5b2ea84af8aa23194a3263052\n",
      "[INFO] [starting] https://msmarco.blob.core.windows.net/msmarcoranking/top1000.train.tar.gz\n",
      "[INFO] [error] https://msmarco.blob.core.windows.net/msmarcoranking/top1000.train.tar.gz: [00:18] [36.3MB] [1.96MB/s] \n",
      "                                                                                                      \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m i,j,k \u001b[39min\u001b[39;00m dataset_torch\u001b[39m.\u001b[39mscoreddocs_iter:\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(i,j,k)\n\u001b[1;32m      3\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/tempory/Information-Retrieval-Project/.venv/lib/python3.9/site-packages/ir_datasets/datasets/base.py:348\u001b[0m, in \u001b[0;36mFilteredScoredDocs.scoreddocs_iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m qids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lazy_qids()\n\u001b[1;32m    344\u001b[0m operator \u001b[39m=\u001b[39m {\n\u001b[1;32m    345\u001b[0m     \u001b[39m'\u001b[39m\u001b[39minclude\u001b[39m\u001b[39m'\u001b[39m: (\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mquery_id \u001b[39min\u001b[39;00m qids),\n\u001b[1;32m    346\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mexclude\u001b[39m\u001b[39m'\u001b[39m: (\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mquery_id \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m qids),\n\u001b[1;32m    347\u001b[0m }[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode]\n\u001b[0;32m--> 348\u001b[0m \u001b[39mfor\u001b[39;00m query \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scoreddocs_handler\u001b[39m.\u001b[39mscoreddocs_iter():\n\u001b[1;32m    349\u001b[0m     \u001b[39mif\u001b[39;00m operator(query):\n\u001b[1;32m    350\u001b[0m         \u001b[39myield\u001b[39;00m query\n",
      "File \u001b[0;32m/tempory/Information-Retrieval-Project/.venv/lib/python3.9/site-packages/ir_datasets/formats/trec.py:501\u001b[0m, in \u001b[0;36mTrecScoredDocs.scoreddocs_iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscoreddocs_iter\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 501\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scoreddocs_dlc\u001b[39m.\u001b[39mstream() \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    502\u001b[0m         f \u001b[39m=\u001b[39m codecs\u001b[39m.\u001b[39mgetreader(\u001b[39m'\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m'\u001b[39m)(f)\n\u001b[1;32m    503\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m f:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/contextlib.py:117\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[1;32m    116\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[1;32m    118\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/tempory/Information-Retrieval-Project/.venv/lib/python3.9/site-packages/ir_datasets/util/fileio.py:78\u001b[0m, in \u001b[0;36mCache.stream\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39m@contextlib\u001b[39m\u001b[39m.\u001b[39mcontextmanager\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstream\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverify()\n\u001b[1;32m     79\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path\u001b[39m.\u001b[39mopen(\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     80\u001b[0m         \u001b[39myield\u001b[39;00m f\n",
      "File \u001b[0;32m/tempory/Information-Retrieval-Project/.venv/lib/python3.9/site-packages/ir_datasets/util/fileio.py:69\u001b[0m, in \u001b[0;36mCache.verify\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_streamer\u001b[39m.\u001b[39mstream() \u001b[39mas\u001b[39;00m stream:\n\u001b[0;32m---> 69\u001b[0m         shutil\u001b[39m.\u001b[39;49mcopyfileobj(stream, f)\n\u001b[1;32m     70\u001b[0m     f\u001b[39m.\u001b[39mclose() \u001b[39m# close file before move... Needed because of Windows\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     shutil\u001b[39m.\u001b[39mmove(f\u001b[39m.\u001b[39mname, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/shutil.py:205\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    203\u001b[0m fdst_write \u001b[39m=\u001b[39m fdst\u001b[39m.\u001b[39mwrite\n\u001b[1;32m    204\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     buf \u001b[39m=\u001b[39m fsrc_read(length)\n\u001b[1;32m    206\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m buf:\n\u001b[1;32m    207\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/tempory/Information-Retrieval-Project/.venv/lib/python3.9/site-packages/ir_datasets/util/fileio.py:35\u001b[0m, in \u001b[0;36mIterStream.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mwhile\u001b[39;00m pos \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(b):\n\u001b[1;32m     34\u001b[0m     l \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(b) \u001b[39m-\u001b[39m pos  \u001b[39m# We're supposed to return at most this much\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     chunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleftover \u001b[39mor\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mit)\n\u001b[1;32m     36\u001b[0m     output, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleftover \u001b[39m=\u001b[39m chunk[:l], chunk[l:]\n\u001b[1;32m     37\u001b[0m     b[pos:pos\u001b[39m+\u001b[39m\u001b[39mlen\u001b[39m(output)] \u001b[39m=\u001b[39m output\n",
      "File \u001b[0;32m/tempory/Information-Retrieval-Project/.venv/lib/python3.9/site-packages/ir_datasets/datasets/msmarco_passage.py:52\u001b[0m, in \u001b[0;36mExtractQidPid.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 52\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_streamer\u001b[39m.\u001b[39mstream() \u001b[39mas\u001b[39;00m stream:\n\u001b[1;32m     53\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m _logger\u001b[39m.\u001b[39mpbar(stream, desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mextracting QID/PID pairs\u001b[39m\u001b[39m'\u001b[39m, unit\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpair\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     54\u001b[0m             qid, did, _, _ \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39msplit(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/contextlib.py:117\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[1;32m    116\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[1;32m    118\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/tempory/Information-Retrieval-Project/.venv/lib/python3.9/site-packages/ir_datasets/util/fileio.py:96\u001b[0m, in \u001b[0;36mTarExtract.stream\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39m@contextlib\u001b[39m\u001b[39m.\u001b[39mcontextmanager\n\u001b[1;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstream\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mwith\u001b[39;00m contextlib\u001b[39m.\u001b[39mExitStack() \u001b[39mas\u001b[39;00m ctxt, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_streamer\u001b[39m.\u001b[39mstream() \u001b[39mas\u001b[39;00m stream:\n\u001b[1;32m     97\u001b[0m         \u001b[39m# IMPORTANT: open this file in streaming mode (| in mode). This means that the\u001b[39;00m\n\u001b[1;32m     98\u001b[0m         \u001b[39m# content need not be written to disk or be fully read.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m         tarf \u001b[39m=\u001b[39m ctxt\u001b[39m.\u001b[39menter_context(tarfile\u001b[39m.\u001b[39mopen(fileobj\u001b[39m=\u001b[39mstream, mode\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mr|\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compression\u001b[39m \u001b[39m\u001b[39mor\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m))\n\u001b[1;32m    100\u001b[0m         \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m tarf:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/contextlib.py:117\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[1;32m    116\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[1;32m    118\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/tempory/Information-Retrieval-Project/.venv/lib/python3.9/site-packages/ir_datasets/util/download.py:275\u001b[0m, in \u001b[0;36mDownload.stream\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[39myield\u001b[39;00m stream\n\u001b[1;32m    274\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 275\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath(), \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    276\u001b[0m         \u001b[39myield\u001b[39;00m f\n",
      "File \u001b[0;32m/tempory/Information-Retrieval-Project/.venv/lib/python3.9/site-packages/ir_datasets/util/download.py:252\u001b[0m, in \u001b[0;36mDownload.path\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[39mwith\u001b[39;00m mirror\u001b[39m.\u001b[39mstream() \u001b[39mas\u001b[39;00m stream:\n\u001b[1;32m    251\u001b[0m             stream \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mHashStream(stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpected_md5, algo\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmd5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 252\u001b[0m             shutil\u001b[39m.\u001b[39;49mcopyfileobj(stream, f)\n\u001b[1;32m    253\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/shutil.py:205\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    203\u001b[0m fdst_write \u001b[39m=\u001b[39m fdst\u001b[39m.\u001b[39mwrite\n\u001b[1;32m    204\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     buf \u001b[39m=\u001b[39m fsrc_read(length)\n\u001b[1;32m    206\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m buf:\n\u001b[1;32m    207\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/tempory/Information-Retrieval-Project/.venv/lib/python3.9/site-packages/ir_datasets/util/hash.py:48\u001b[0m, in \u001b[0;36mHashStream.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreadinto\u001b[39m(\u001b[39mself\u001b[39m, b):\n\u001b[0;32m---> 48\u001b[0m     count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m     49\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verifier\u001b[39m.\u001b[39mupdate(b[:count])\n\u001b[1;32m     50\u001b[0m     \u001b[39mif\u001b[39;00m count \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/tempory/Information-Retrieval-Project/.venv/lib/python3.9/site-packages/ir_datasets/util/fileio.py:35\u001b[0m, in \u001b[0;36mIterStream.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mwhile\u001b[39;00m pos \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(b):\n\u001b[1;32m     34\u001b[0m     l \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(b) \u001b[39m-\u001b[39m pos  \u001b[39m# We're supposed to return at most this much\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     chunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleftover \u001b[39mor\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mit)\n\u001b[1;32m     36\u001b[0m     output, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleftover \u001b[39m=\u001b[39m chunk[:l], chunk[l:]\n\u001b[1;32m     37\u001b[0m     b[pos:pos\u001b[39m+\u001b[39m\u001b[39mlen\u001b[39m(output)] \u001b[39m=\u001b[39m output\n",
      "File \u001b[0;32m/tempory/Information-Retrieval-Project/.venv/lib/python3.9/site-packages/ir_datasets/util/download.py:97\u001b[0m, in \u001b[0;36mRequestsDownload.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m         pbar_f \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m# defaults to stderr\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     pbar \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(_logger\u001b[39m.\u001b[39mpbar_raw(desc\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl, total\u001b[39m=\u001b[39mdlen, unit\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mB\u001b[39m\u001b[39m'\u001b[39m, unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, bar_format\u001b[39m=\u001b[39mfmt, file\u001b[39m=\u001b[39mpbar_f))\n\u001b[0;32m---> 97\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_response_data(response, http_args, skip):\n\u001b[1;32m     98\u001b[0m     pbar\u001b[39m.\u001b[39mupdate(\u001b[39mlen\u001b[39m(data))\n\u001b[1;32m     99\u001b[0m     \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39maccept-ranges\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbytes\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    100\u001b[0m         \u001b[39m# since we got more data and the server accepts range requests, reset the \"tries\" counter\u001b[39;00m\n",
      "File \u001b[0;32m/tempory/Information-Retrieval-Project/.venv/lib/python3.9/site-packages/ir_datasets/util/download.py:145\u001b[0m, in \u001b[0;36mRequestsDownload._iter_response_data\u001b[0;34m(self, response, http_args, skip)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     data_iter \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39mio\u001b[39m.\u001b[39mDEFAULT_BUFFER_SIZE)\n\u001b[0;32m--> 145\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m data_iter:\n\u001b[1;32m    146\u001b[0m     \u001b[39mif\u001b[39;00m skip \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    147\u001b[0m         data, skipped \u001b[39m=\u001b[39m data[skip:], \u001b[39mlen\u001b[39m(data[:skip])\n",
      "File \u001b[0;32m/tempory/Information-Retrieval-Project/.venv/lib/python3.9/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m/tempory/Information-Retrieval-Project/.venv/lib/python3.9/site-packages/urllib3/response.py:628\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp):\n\u001b[0;32m--> 628\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[1;32m    630\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[1;32m    631\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m/tempory/Information-Retrieval-Project/.venv/lib/python3.9/site-packages/urllib3/response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    564\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    566\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 567\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m         flush_decoder \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/tempory/Information-Retrieval-Project/.venv/lib/python3.9/site-packages/urllib3/response.py:525\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    524\u001b[0m     chunk_amt \u001b[39m=\u001b[39m max_chunk_amt\n\u001b[0;32m--> 525\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(chunk_amt)\n\u001b[1;32m    526\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data:\n\u001b[1;32m    527\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/http/client.py:459\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     \u001b[39m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     b \u001b[39m=\u001b[39m \u001b[39mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 459\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b)[:n]\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    461\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[39m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[39m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/http/client.py:503\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    498\u001b[0m         b \u001b[39m=\u001b[39m \u001b[39mmemoryview\u001b[39m(b)[\u001b[39m0\u001b[39m:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength]\n\u001b[1;32m    500\u001b[0m \u001b[39m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[39m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[39m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m n \u001b[39mand\u001b[39;00m b:\n\u001b[1;32m    505\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1242\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i,j,k in dataset_torch.scoreddocs_iter:\n",
    "    print(i,j,k)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
