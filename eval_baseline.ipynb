{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/RI/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from load_dataset import load_corpus, load_queries\n",
    "from crossencoder_bm25 import CustomCrossEncoder\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "import pickle\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On lit les passages retrieve par BM25 (top 1000) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8.84Mit [00:14, 600kit/s]\n",
      "6.98kit [00:00, 1.23Mit/s]\n",
      "6.97Mit [00:17, 390kit/s] \n"
     ]
    }
   ],
   "source": [
    "data_folder = \"./data/msmarco-passage/\"\n",
    "corpus = load_corpus(os.path.join(data_folder, \"collection.tsv\"))\n",
    "queries = load_queries(os.path.join(data_folder, \"queries.dev.small.tsv\"))\n",
    "\n",
    "import gzip\n",
    "\n",
    "\n",
    "def load_retrieval(retrieval_filepath, corpus, queries):\n",
    "    retrieval_samples = {}\n",
    "    with gzip.open(retrieval_filepath, \"rt\") as fIn:\n",
    "        for line in tqdm(fIn, unit_scale=True):\n",
    "            qid, corpus_id, rank, bm25_score = line.strip().split(\"\\t\")\n",
    "\n",
    "            query = queries[qid]\n",
    "            passage = corpus[corpus_id]\n",
    "\n",
    "            if qid in retrieval_samples:\n",
    "                retrieval_samples[qid].append([query, passage])\n",
    "            else:\n",
    "                retrieval_samples[qid] = [[query, passage]]\n",
    "\n",
    "    return retrieval_samples\n",
    "\n",
    "\n",
    "retrieval_samples = load_retrieval(\n",
    "    os.path.join(data_folder, \"msmarco.bm25.dev.small.tsv.gz\"), corpus, queries\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisation du Cross-Encoder (CEBM25CAT) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"output/training_ms-marco_cross-encoder-microsoft-MiniLM-L12-H384-uncased-2023-05-09_18-21-03-latest\"\n",
    "model = CrossEncoder(model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Ranking :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6980 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      " 58%|█████▊    | 4034/6980 [1:01:48<46:18,  1.06it/s]"
     ]
    }
   ],
   "source": [
    "similarity_scores = {}\n",
    "for qid in tqdm(queries):\n",
    "    similarity_scores[qid] = [model.predict(retrieval_samples[qid])]\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On save parce que c'est long :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"reranking_baseline.pkl\"):\n",
    "    with open('reranking_baseline.pkl', 'wb') as f:\n",
    "        pickle.dump(similarity_scores, f)\n",
    "else:\n",
    "    with open('reranking_baseline.pkl', 'rb') as f:\n",
    "        similarity_scores = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant on prépare les données pour pouvoir calculer les métriques..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6.97Mit [00:12, 558kit/s] \n"
     ]
    }
   ],
   "source": [
    "dev_filepath = \"runs/run.msmarco-passage.bm25tuned.txt\"\n",
    "dev = {}\n",
    "\n",
    "with open(dev_filepath, \"r\") as fIn:\n",
    "    for line in tqdm(fIn, unit_scale=True):\n",
    "        qid, corpus_id, rank = line.strip().split(\"\\t\")\n",
    "        \n",
    "        if qid in dev:\n",
    "            dev[qid].append([qid, corpus_id])\n",
    "        else:\n",
    "            dev[qid] = [[qid, corpus_id]]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il ne faut pas oublier de sort :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [np.concatenate((np.array(dev[qid]), similarity_scores[qid][0].reshape(-1, 1)), axis=1) for qid in queries]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1048585', '7187158', '0.99066484'],\n",
       "       ['1048585', '7187157', '0.9708628'],\n",
       "       ['1048585', '7187163', '0.94394267'],\n",
       "       ...,\n",
       "       ['1048585', '5771111', '0.00012813006'],\n",
       "       ['1048585', '6073381', '0.000110037196'],\n",
       "       ['1048585', '6339403', '0.000116001946']], dtype='<U32')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_sorted = [results[i][results[i][:, 2].argsort()[::-1]] for i in range(len(results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1048585', '7187155', '0.99207896'],\n",
       "       ['1048585', '7187158', '0.99066484'],\n",
       "       ['1048585', '7187160', '0.9873302'],\n",
       "       ...,\n",
       "       ['1048585', '7012534', '0.000107882675'],\n",
       "       ['1048585', '8593160', '0.00010783897'],\n",
       "       ['1048585', '6516178', '0.00010779846']], dtype='<U32')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_sorted[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et on peut enfin sauvegarder les résultats pour Pyserini :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"run.msmarco-passage.reranking.baseline.txt\", \"w\") as fOut:\n",
    "    writer = csv.writer(fOut, delimiter=\"\\t\", lineterminator=\"\\n\")\n",
    "    for result in results_sorted:\n",
    "        for rank, line in enumerate(result):\n",
    "            qid = line[0]\n",
    "            corpus_id = line[1]\n",
    "            writer.writerow([qid, corpus_id, rank + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
